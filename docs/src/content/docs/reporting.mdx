---
title: Reporting
description: Output formats, chart generation, and CI integration for poly-bench results
---

<div data-pagefind-weight="8">

### Overview

poly-bench provides multiple output formats to fit different workflows: colorful console tables for development, markdown for documentation, JSON for CI pipelines, and SVG charts for visual comparisons.

| Format | Use Case | Flag |
|--------|----------|------|
| Console | Development, quick iteration | (default) |
| Markdown | Documentation, GitHub PRs | `--report markdown` |
| JSON | CI/CD, automation, custom tooling | `--report json` |
| SVG Charts | Visual comparison, presentations | Via `charting.*` directives |

</div>

### Console Output

The default console output provides a formatted, colored view of benchmark results:

<CodeGroup 
  tabs={[
    {
      title: "Output",
      language: "text",
      code: `Running suite: keccak
  Calibrating iterations...
  Target time: 3000ms
  Calibrated to: 2,430,000 iterations
  
  Running: keccak256Bench (run 1/3)
    go:   1,234 ns/op (810,372 ops/s) ± 2.1%
    ts:   15,678 ns/op (63,784 ops/s) ± 3.4%
    rust: 987 ns/op (1,013,171 ops/s) ± 1.8%

  Running: keccak256Bench (run 2/3)
    go:   1,198 ns/op (834,725 ops/s) ± 1.9%
    ts:   15,432 ns/op (64,800 ops/s) ± 2.8%
    rust: 1,002 ns/op (998,004 ops/s) ± 2.0%

  Running: keccak256Bench (run 3/3)
    go:   1,215 ns/op (823,045 ops/s) ± 2.3%
    ts:   15,890 ns/op (62,933 ops/s) ± 3.1%
    rust: 991 ns/op (1,009,082 ops/s) ± 1.6%

  ─────────────────────────────────────────────
  Summary: keccak256Bench
  ─────────────────────────────────────────────
  
  │ Lang │ Mean (ns/op) │ Std Dev │ Ops/s    │
  ├──────┼──────────────┼─────────┼──────────┤
  │ rust │ 993          │ ± 1.8%  │ 1,006,752│
  │ go   │ 1,216        │ ± 2.1%  │ 822,714  │
  │ ts   │ 15,667       │ ± 3.1%  │ 63,839   │

  Comparison (baseline: go):
    rust: 1.22x faster
    ts:   12.88x slower

  ✓ Suite completed in 9.2s`
    },
  ]}
/>

<Aside type="tip">
<span>The console output is automatically colored when running in a terminal. Use <code>--no-color</code> to disable colors for piping to files or logs.</span>
</Aside>


### Markdown Reports

Generate markdown reports for documentation or GitHub pull requests:

<CodeGroup 
  tabs={[
    {
      title: "Terminal",
      language: "bash",
      code: `poly-bench run benchmarks/keccak.bench --report markdown --output results/`
    },
  ]}
/>

This generates `results/benchmark-report.md`:

<CodeGroup 
  tabs={[
    {
      title: "benchmark-report.md",
      language: "markdown",
      code: `# Benchmark Report

## Suite: keccak

**Description:** Keccak256 hash benchmark

**Configuration:**
- Mode: auto (target: 3000ms)
- Warmup: 100 iterations
- Runs: 3
- Baseline: go

### Results

| Benchmark | Go (ns/op) | TS (ns/op) | Rust (ns/op) |
|-----------|------------|------------|--------------|
| keccak256Bench | 1,216 ± 2.1% | 15,667 ± 3.1% | 993 ± 1.8% |

### Comparison

| Benchmark | Go | TypeScript | Rust |
|-----------|-----|------------|------|
| keccak256Bench | baseline | 12.88x slower | 1.22x faster |

### Statistics

| Metric | Go | TypeScript | Rust |
|--------|-----|------------|------|
| Mean (ns/op) | 1,216 | 15,667 | 993 |
| Ops/s | 822,714 | 63,839 | 1,006,752 |
| Std Dev | ± 2.1% | ± 3.1% | ± 1.8% |

*Generated by poly-bench v0.0.22*`
    },
  ]}
/>


### JSON Output

For CI/CD pipelines and automation, output results as JSON:

<CodeGroup 
  tabs={[
    {
      title: "Terminal",
      language: "bash",
      code: `poly-bench run benchmarks/keccak.bench --report json --output results/`
    },
  ]}
/>

This generates `results/benchmark-results.json`:

<CodeGroup 
  tabs={[
    {
      title: "benchmark-results.json",
      language: "json",
      code: `{
  "version": "0.0.22",
  "timestamp": "2024-01-15T10:30:00Z",
  "suites": [
    {
      "name": "keccak",
      "description": "Keccak256 hash benchmark",
      "config": {
        "mode": "auto",
        "targetTime": 3000,
        "warmup": 100,
        "count": 3,
        "baseline": "go"
      },
      "benchmarks": [
        {
          "name": "keccak256Bench",
          "results": {
            "go": {
              "meanNsPerOp": 1216,
              "stdDev": 0.021,
              "opsPerSec": 822714,
              "runs": [1234, 1198, 1215],
              "memory": null
            },
            "ts": {
              "meanNsPerOp": 15667,
              "stdDev": 0.031,
              "opsPerSec": 63839,
              "runs": [15678, 15432, 15890],
              "memory": null
            },
            "rust": {
              "meanNsPerOp": 993,
              "stdDev": 0.018,
              "opsPerSec": 1006752,
              "runs": [987, 1002, 991],
              "memory": null
            }
          },
          "comparisons": {
            "rust": { "ratio": 0.817, "label": "1.22x faster" },
            "ts": { "ratio": 12.88, "label": "12.88x slower" }
          }
        }
      ]
    }
  ]
}`
    },
  ]}
/>

<Aside type="note">
<span>JSON output is ideal for tracking performance regressions in CI. Parse the results and fail builds when performance degrades beyond a threshold.</span>
</Aside>


### SVG Chart Generation

poly-bench can generate SVG charts directly from benchmark results using the `charting` standard library module.

Add chart directives to your benchmark's `after` block:

<CodeGroup 
  tabs={[
    {
      title: ".bench",
      language: "rust",
      code: `use std::charting

suite keccak {
    // ... benchmark config and setup ...

    bench keccak256Bench {
        go: keccak256Go(data)
        ts: keccak256Ts(data)
        rust: keccak256_rust(&data)
    }

    after {
        charting.drawBarChart(
            title: "Keccak256 Performance",
            xlabel: "Implementation"
        )
    }
}`
    },
  ]}
/>

Run with an output directory to generate the chart:

<CodeGroup 
  tabs={[
    {
      title: "Terminal",
      language: "bash",
      code: `poly-bench run benchmarks/keccak.bench --output results/`
    },
  ]}
/>

This generates `results/keccak256-performance.svg`.

### Available Chart Types

| Directive | Description |
|-----------|-------------|
| `charting.drawBarChart(...)` | Horizontal or vertical bar chart comparing languages |
| `charting.drawPieChart(...)` | Pie chart showing relative performance distribution |
| `charting.drawLineChart(...)` | Line chart for scaling benchmarks (e.g., by input size) |

<Aside type="tip">
<span>Charts are styled automatically with a clean, readable design. They work well in both light and dark documentation themes.</span>
</Aside>


### Comparison Tables

Enable automatic comparison tables with the `compare` and `baseline` options:

<CodeGroup 
  tabs={[
    {
      title: ".bench",
      language: "rust",
      code: `suite myBenchmarks {
    compare: true       // Enable comparison table
    baseline: "go"      // Use Go as the baseline (1.0x)
    
    // ... rest of suite
}`
    },
  ]}
/>

The comparison shows speedup/slowdown ratios relative to the baseline:

<CodeGroup 
  tabs={[
    {
      title: "Output",
      language: "text",
      code: `  Comparison (baseline: go):
    rust: 1.22x faster
    ts:   12.88x slower`
    },
  ]}
/>


### Statistical Options

Control the statistical rigor of your benchmarks:

| Option | Description | Default |
|--------|-------------|---------|
| `warmup` | Iterations before timing starts | 0 |
| `count` | Number of runs per benchmark | 1 |
| `outlierDetection` | IQR-based outlier removal | false |
| `cvThreshold` | Target coefficient of variation (%) | - |

<CodeGroup 
  tabs={[
    {
      title: ".bench",
      language: "rust",
      code: `suite rigorous {
    warmup: 1000              // 1000 warmup iterations
    count: 5                  // 5 runs per benchmark
    outlierDetection: true    // Remove statistical outliers
    cvThreshold: 5            // Re-run if CV > 5%
    
    // ... rest of suite
}`
    },
  ]}
/>

<Aside type="note">
<span>Setting <code>cvThreshold</code> will cause poly-bench to re-run benchmarks until the coefficient of variation is below the threshold, ensuring more stable results.</span>
</Aside>


### Memory Profiling

Track memory allocations alongside timing:

<CodeGroup 
  tabs={[
    {
      title: ".bench",
      language: "rust",
      code: `suite withMemory {
    memory: true    // Enable memory profiling
    
    // ... rest of suite
}`
    },
  ]}
/>

Memory results appear in the output:

<CodeGroup 
  tabs={[
    {
      title: "Output",
      language: "text",
      code: `  Running: keccak256Bench
    go:   1,234 ns/op (810,372 ops/s) ± 2.1%  |  96 B/op, 2 allocs/op
    ts:   15,678 ns/op (63,784 ops/s) ± 3.4%  |  1,024 B/op
    rust: 987 ns/op (1,013,171 ops/s) ± 1.8%  |  0 B/op, 0 allocs/op`
    },
  ]}
/>


### CI Integration

Example GitHub Actions workflow for performance regression testing:

<CodeGroup 
  tabs={[
    {
      title: ".github/workflows/bench.yml",
      language: "yaml",
      code: `name: Benchmarks

on:
  pull_request:
    branches: [main]

jobs:
  benchmark:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Install poly-bench
        run: cargo install poly-bench
      
      - name: Setup languages
        run: |
          # Go is pre-installed
          # Node.js is pre-installed
          rustup default stable
      
      - name: Install dependencies
        run: poly-bench install
      
      - name: Run benchmarks
        run: poly-bench run --report json --output results/
      
      - name: Upload results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: results/`
    },
  ]}
/>


### Next Steps

- Learn the full [DSL Reference](/docs/core/dsl-reference) for benchmark configuration
- Explore [Examples](/docs/examples) for common benchmark patterns
- Check the [CLI Reference](/docs/tools/cli) for all output options
