//! Go plugin source code generation

use poly_bench_dsl::{Lang, BenchMode};
use poly_bench_ir::{BenchmarkIR, SuiteIR, BenchmarkSpec, FixtureIR};
use poly_bench_stdlib as stdlib;
use miette::{Result, miette};

use super::shared::{
    self, CollectedImports, SinkMemoryDecls, BENCH_RESULT_STRUCT,
    generate_bench_call, generate_suite_code,
};

/// Generate Go plugin source code from IR
pub fn generate(ir: &BenchmarkIR) -> Result<String> {
    let mut code = String::new();

    // Package declaration
    code.push_str("// Code generated by poly-bench. DO NOT EDIT.\n\npackage main\n\n");
    
    // Collect all user imports from all suites
    let mut user_imports: Vec<&str> = Vec::new();
    for suite in &ir.suites {
        if let Some(imports) = suite.imports.get(&Lang::Go) {
            for import_spec in imports {
                user_imports.push(import_spec);
            }
        }
    }
    
    // Collect stdlib imports
    let stdlib_imports = stdlib::get_stdlib_imports(&ir.stdlib_imports, Lang::Go);
    
    // Check if any benchmark uses sink pattern or memory profiling
    let needs_runtime = ir.suites.iter().any(|suite| {
        suite.benchmarks.iter().any(|bench| (bench.use_sink || bench.memory) && bench.has_lang(Lang::Go))
    });
    
    // Check if any benchmark uses concurrency
    let needs_sync = ir.suites.iter().any(|suite| {
        suite.benchmarks.iter().any(|bench| bench.concurrency > 1 && bench.has_lang(Lang::Go))
    });

    // Generate import block using shared utility
    let imports = CollectedImports::for_ir(&user_imports, &stdlib_imports, needs_runtime, needs_sync);
    code.push_str(&imports.generate_import_block());

    // Inject stdlib code if any modules are imported
    let stdlib_code = stdlib::get_stdlib_code(&ir.stdlib_imports, Lang::Go);
    if !stdlib_code.is_empty() {
        code.push_str(&stdlib_code);
        code.push_str("\n");
    }

    // BenchResult type with plugin exports
    code.push_str("// BenchResult holds the benchmark measurement results\n");
    code.push_str(BENCH_RESULT_STRUCT);
    code.push_str("\n// Export symbols for plugin loading\nvar (\n\tRunBenchmark  = runBenchmark\n\tListBenchmarks = listBenchmarks\n)\n\n");

    // Generate code for each suite
    for suite in &ir.suites {
        generate_suite(&mut code, suite)?;
    }

    // Generate the main runner function
    generate_runner_function(&mut code, ir);

    Ok(code)
}

/// Generate the plugin runner functions
fn generate_runner_function(code: &mut String, ir: &BenchmarkIR) {
    code.push_str(r#"
// runBenchmark executes a benchmark by name and returns JSON results
func runBenchmark(name string, iterations int) string {
	var result BenchResult

	switch name {
"#);

    for suite in &ir.suites {
        for bench in &suite.benchmarks {
            if bench.has_lang(Lang::Go) {
                code.push_str(&format!(
                    "\tcase \"{}\":\n\t\tresult = bench_{}(iterations)\n",
                    bench.full_name, bench.full_name
                ));
            }
        }
    }

    code.push_str(r#"	default:
		result = BenchResult{}
	}

	jsonBytes, _ := json.Marshal(result)
	return string(jsonBytes)
}

// listBenchmarks returns a JSON array of available benchmark names
func listBenchmarks() string {
	names := []string{
"#);

    for suite in &ir.suites {
        for bench in &suite.benchmarks {
            if bench.has_lang(Lang::Go) {
                code.push_str(&format!("\t\t\"{}\",\n", bench.full_name));
            }
        }
    }

    code.push_str(r#"	}
	jsonBytes, _ := json.Marshal(names)
	return string(jsonBytes)
}

func main() {}
"#);
}

/// Generate code for a single suite
fn generate_suite(code: &mut String, suite: &SuiteIR) -> Result<()> {
    // Use shared suite code generation
    code.push_str(&generate_suite_code(suite, Lang::Go));

    // Generate fixtures
    for fixture in &suite.fixtures {
        generate_fixture(code, fixture)?;
    }

    // Generate benchmark functions
    for bench in &suite.benchmarks {
        if bench.has_lang(Lang::Go) {
            generate_benchmark(code, bench, suite)?;
        }
    }

    Ok(())
}

/// Generate a fixture variable
fn generate_fixture(code: &mut String, fixture: &FixtureIR) -> Result<()> {
    if let Some(impl_code) = fixture.implementations.get(&Lang::Go) {
        code.push_str(&format!("// Fixture: {}\n", fixture.name));
        if let Some(ref desc) = fixture.description {
            code.push_str(&format!("// {}\n", desc));
        }
        code.push_str(&format!("var {} = {}\n\n", fixture.name, impl_code));
    } else if !fixture.data.is_empty() {
        code.push_str(&format!("// Fixture: {}\n", fixture.name));
        if let Some(ref desc) = fixture.description {
            code.push_str(&format!("// {}\n", desc));
        }
        code.push_str(&format!("var {} = {}\n\n", fixture.name, fixture.as_go_bytes()));
    }
    Ok(())
}

/// Generate a benchmark function
fn generate_benchmark(code: &mut String, bench: &BenchmarkSpec, _suite: &SuiteIR) -> Result<()> {
    let impl_code = bench.get_impl(Lang::Go)
        .ok_or_else(|| miette!("No Go implementation for benchmark {}", bench.name))?;

    code.push_str(&format!("// Benchmark: {}\n", bench.name));
    if let Some(ref desc) = bench.description {
        code.push_str(&format!("// {}\n", desc));
    }

    // Use shared utilities for sink/memory declarations
    let decls = SinkMemoryDecls::from_spec(bench);
    let bench_call = generate_bench_call(impl_code, bench.use_sink);
    
    // Generate hook code
    let before_hook = bench.before_hooks.get(&Lang::Go)
        .map(|h| format!("\t// Before hook\n\t{}\n\n", h.trim()))
        .unwrap_or_default();
    let after_hook = bench.after_hooks.get(&Lang::Go)
        .map(|h| format!("\n\t// After hook\n\t{}\n", h.trim()))
        .unwrap_or_default();
    let each_hook = bench.each_hooks.get(&Lang::Go);
    let each_hook_code = each_hook
        .map(|h| format!("\t\t\t{}\n", h.trim()))
        .unwrap_or_default();

    // Memory result fields
    let memory_result = SinkMemoryDecls::memory_result_fields(bench.memory, "totalIterations");
    
    // Concurrent execution
    if bench.concurrency > 1 {
        return generate_concurrent_benchmark(code, bench, &before_hook, &after_hook, &bench_call, decls.sink_decl, decls.memory_decl, decls.memory_before, decls.memory_after);
    }

    match bench.mode {
        BenchMode::Auto => {
            code.push_str(&format!(r#"func bench_{}(iterations int) BenchResult {{
	// Auto-calibration mode: iterations parameter is ignored, runs for targetTime
	targetNanos := int64({})
{}{}
{}{}	// Brief warmup (100 iterations)
	for i := 0; i < 100; i++ {{
{}		{}
{}	}}
	
{}
	nanosPerOp := float64(totalNanos) / float64(totalIterations)
	opsPerSec := 1e9 / nanosPerOp
	
{}
{}
	return BenchResult{{
		Iterations:  uint64(totalIterations),
		TotalNanos:  uint64(totalNanos),
		NanosPerOp:  nanosPerOp,
		OpsPerSec:   opsPerSec,
{}		Samples:     samples,
	}}
}}

"#, 
                bench.full_name, 
                bench.target_time_ms * 1_000_000,
                decls.sink_decl, 
                decls.memory_decl, 
                before_hook, 
                decls.memory_before,
                each_hook_code, 
                bench_call, 
                decls.sink_keepalive,
                shared::generate_auto_mode_loop(&bench_call, decls.sink_keepalive, each_hook, bench.target_time_ms),
                shared::generate_sample_collection(&bench_call, decls.sink_keepalive, each_hook, "1000", "totalIterations"),
                after_hook,
                memory_result,
            ));
        }
        BenchMode::Fixed => {
            let memory_result_fixed = SinkMemoryDecls::memory_result_fields(bench.memory, "iterations");
            
            code.push_str(&format!(r#"func bench_{}(iterations int) BenchResult {{
	samples := make([]uint64, iterations)
{}{}
{}{}{}
{}
{}{}
	nanosPerOp := float64(totalNanos) / float64(iterations)
	opsPerSec := 1e9 / nanosPerOp

	return BenchResult{{
		Iterations:  uint64(iterations),
		TotalNanos:  totalNanos,
		NanosPerOp:  nanosPerOp,
		OpsPerSec:   opsPerSec,
{}		Samples:     samples,
	}}
}}

"#, 
                bench.full_name,
                decls.sink_decl,
                decls.memory_decl,
                before_hook,
                decls.memory_before,
                shared::generate_warmup_loop(&bench_call, decls.sink_keepalive, each_hook, &bench.warmup.to_string()),
                shared::generate_fixed_mode_loop(&bench_call, decls.sink_keepalive, each_hook, "iterations"),
                decls.memory_after,
                after_hook,
                memory_result_fixed,
            ));
        }
    }

    Ok(())
}

/// Generate a concurrent benchmark function using goroutines
fn generate_concurrent_benchmark(
    code: &mut String,
    bench: &BenchmarkSpec,
    before_hook: &str,
    after_hook: &str,
    bench_call: &str,
    sink_decl: &str,
    memory_decl: &str,
    memory_before: &str,
    memory_after: &str,
) -> Result<()> {
    let concurrency = bench.concurrency;
    let memory_result = SinkMemoryDecls::memory_result_fields(bench.memory, "totalIterations");
    let sink_keepalive = if bench.use_sink { "\truntime.KeepAlive(__sink)\n" } else { "" };
    
    code.push_str(&format!(r#"func bench_{}(iterations int) BenchResult {{
{}{}
{}{}
{}
{}{}
	nanosPerOp := float64(totalNanos) / float64(totalIterations)
	opsPerSec := 1e9 / nanosPerOp
	
{}
{}
	return BenchResult{{
		Iterations:  uint64(totalIterations),
		TotalNanos:  uint64(totalNanos),
		NanosPerOp:  nanosPerOp,
		OpsPerSec:   opsPerSec,
{}		Samples:     samples,
	}}
}}

"#, 
        bench.full_name,
        sink_decl,
        memory_decl,
        before_hook,
        memory_before,
        shared::generate_concurrent_execution(bench_call, bench_call, concurrency, "iterations"),
        sink_keepalive,
        memory_after,
        shared::generate_sample_collection(bench_call, "", None, "100", "totalIterations"),
        after_hook,
        memory_result,
    ));
    
    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;
    use poly_bench_dsl::parse;
    use poly_bench_ir::lower;

    #[test]
    fn test_generate_simple() {
        let source = r#"
suite hash {
    iterations: 1000
    warmup: 10
    
    fixture data {
        hex: "deadbeef"
    }
    
    bench keccak256 {
        go: keccak256(data)
    }
}
"#;
        let ast = parse(source, "test.bench").unwrap();
        let ir = lower(&ast, None).unwrap();
        let code = generate(&ir).unwrap();
        
        assert!(code.contains("package main"));
        assert!(code.contains("func bench_hash_keccak256"));
        assert!(code.contains("var data = []byte{0xde, 0xad, 0xbe, 0xef}"));
    }

    #[test]
    fn test_generate_with_stdlib_constants() {
        let source = r#"
use std::constants

suite math {
    iterations: 100
    
    bench pi_calc {
        go: compute(std_PI)
    }
}
"#;
        let ast = parse(source, "test.bench").unwrap();
        let ir = lower(&ast, None).unwrap();
        let code = generate(&ir).unwrap();
        
        assert!(code.contains("std_PI"));
        assert!(code.contains("std_E"));
        assert!(code.contains("float64"));
        assert!(code.contains("3.14159"));
    }

    #[test]
    fn test_generate_without_stdlib() {
        let source = r#"
suite test {
    iterations: 100
    
    fixture data {
        hex: "deadbeef"
    }
    
    bench simple {
        go: test(data)
    }
}
"#;
        let ast = parse(source, "test.bench").unwrap();
        let ir = lower(&ast, None).unwrap();
        let code = generate(&ir).unwrap();
        
        assert!(!code.contains("std_PI"));
        assert!(!code.contains("std_E"));
    }
}
