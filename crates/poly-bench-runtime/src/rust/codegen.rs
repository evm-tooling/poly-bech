//! Rust benchmark source code generation

use miette::{miette, Result};
use poly_bench_dsl::{BenchMode, Lang};
use poly_bench_ir::{BenchmarkIR, BenchmarkSpec, FixtureIR, SuiteIR};
use poly_bench_stdlib as stdlib;

use super::shared::{
    self, generate_bench_call, generate_suite_code, CollectedImports, SinkMemoryDecls,
    BENCH_RESULT_STRUCT,
};

/// Generate Rust benchmark source code from IR
pub fn generate(ir: &BenchmarkIR) -> Result<String> {
    let mut code = String::new();

    // Header comment
    code.push_str("// Code generated by poly-bench. DO NOT EDIT.\n\n");

    // Collect all user imports from all suites
    let mut user_imports: Vec<&str> = Vec::new();
    for suite in &ir.suites {
        if let Some(imports) = suite.imports.get(&Lang::Rust) {
            for import_spec in imports {
                user_imports.push(import_spec);
            }
        }
    }

    // Collect stdlib imports
    let stdlib_imports = stdlib::get_stdlib_imports(&ir.stdlib_imports, Lang::Rust);

    // Check if any benchmark uses memory profiling
    let _needs_memory = ir.suites.iter().any(|suite| {
        suite
            .benchmarks
            .iter()
            .any(|bench| bench.memory && bench.has_lang(Lang::Rust))
    });

    // Check if any benchmark uses concurrency
    let needs_sync = ir.suites.iter().any(|suite| {
        suite.benchmarks.iter().any(|bench| bench.concurrency > 1 && bench.has_lang(Lang::Rust))
    });

    // Generate use statements
    let imports = CollectedImports::for_ir(&user_imports, &stdlib_imports, false, needs_sync);
    code.push_str(&imports.generate_use_block());

    // Inject stdlib code if any modules are imported
    let stdlib_code = stdlib::get_stdlib_code(&ir.stdlib_imports, Lang::Rust);
    if !stdlib_code.is_empty() {
        code.push_str(&stdlib_code);
        code.push_str("\n");
    }

    // BenchResult struct
    code.push_str("// BenchResult holds the benchmark measurement results\n");
    code.push_str(BENCH_RESULT_STRUCT);
    code.push('\n');

    // Generate code for each suite
    for suite in &ir.suites {
        generate_suite(&mut code, suite)?;
    }

    // Generate the main function with benchmark dispatch
    generate_main_function(&mut code, ir);

    Ok(code)
}

/// Generate the main function with benchmark dispatch
fn generate_main_function(code: &mut String, ir: &BenchmarkIR) {
    code.push_str(
        r#"
fn main() {
    let args: Vec<String> = std::env::args().collect();
    
    if args.len() < 2 {
        eprintln!("Usage: {} <benchmark_name> [iterations]", args[0]);
        std::process::exit(1);
    }
    
    let name = &args[1];
    let iterations: i64 = args.get(2)
        .and_then(|s| s.parse().ok())
        .unwrap_or(1000);
    
    let result = match name.as_str() {
"#,
    );

    for suite in &ir.suites {
        for bench in &suite.benchmarks {
            if bench.has_lang(Lang::Rust) {
                code.push_str(&format!(
                    "        \"{}\" => bench_{}(iterations),\n",
                    bench.full_name, bench.full_name.replace('.', "_")
                ));
            }
        }
    }

    code.push_str(
        r#"        _ => {
            eprintln!("Unknown benchmark: {}", name);
            std::process::exit(1);
        }
    };
    
    println!("{}", serde_json::to_string(&result).unwrap());
}
"#,
    );
}

/// Generate code for a single suite
fn generate_suite(code: &mut String, suite: &SuiteIR) -> Result<()> {
    // Use shared suite code generation
    code.push_str(&generate_suite_code(suite, Lang::Rust));

    // Generate fixtures
    for fixture in &suite.fixtures {
        generate_fixture(code, fixture)?;
    }

    // Generate benchmark functions
    for bench in &suite.benchmarks {
        if bench.has_lang(Lang::Rust) {
            generate_benchmark(code, bench, suite)?;
        }
    }

    Ok(())
}

/// Generate a fixture constant
fn generate_fixture(code: &mut String, fixture: &FixtureIR) -> Result<()> {
    if let Some(impl_code) = fixture.implementations.get(&Lang::Rust) {
        code.push_str(&format!("// Fixture: {}\n", fixture.name));
        if let Some(ref desc) = fixture.description {
            code.push_str(&format!("// {}\n", desc));
        }
        // Use lazy_static for complex fixtures
        code.push_str(&format!(
            "fn get_fixture_{}() -> impl AsRef<[u8]> {{\n    {}\n}}\n\n",
            fixture.name, impl_code
        ));
    } else if !fixture.data.is_empty() {
        code.push_str(&format!("// Fixture: {}\n", fixture.name));
        if let Some(ref desc) = fixture.description {
            code.push_str(&format!("// {}\n", desc));
        }
        code.push_str(&format!(
            "const {}: &[u8] = &[{}];\n\n",
            fixture.name.to_uppercase(),
            fixture.as_rust_bytes()
        ));
    }
    Ok(())
}

/// Generate a benchmark function
fn generate_benchmark(code: &mut String, bench: &BenchmarkSpec, _suite: &SuiteIR) -> Result<()> {
    let impl_code = bench
        .get_impl(Lang::Rust)
        .ok_or_else(|| miette!("No Rust implementation for benchmark {}", bench.name))?;

    code.push_str(&format!("// Benchmark: {}\n", bench.name));
    if let Some(ref desc) = bench.description {
        code.push_str(&format!("// {}\n", desc));
    }

    let fn_name = bench.full_name.replace('.', "_");

    // Use shared utilities for sink/memory declarations
    let decls = SinkMemoryDecls::from_spec(bench);
    let bench_call = generate_bench_call(impl_code, bench.use_sink);

    // Generate hook code
    let before_hook = bench
        .before_hooks
        .get(&Lang::Rust)
        .map(|h| format!("    // Before hook\n    {}\n\n", h.trim()))
        .unwrap_or_default();
    let after_hook = bench
        .after_hooks
        .get(&Lang::Rust)
        .map(|h| format!("\n    // After hook\n    {}\n", h.trim()))
        .unwrap_or_default();
    let each_hook = bench.each_hooks.get(&Lang::Rust);

    // Memory result fields
    let memory_result = SinkMemoryDecls::memory_result_fields(bench.memory);

    // Concurrent execution
    if bench.concurrency > 1 {
        return generate_concurrent_benchmark(
            code,
            bench,
            &fn_name,
            &before_hook,
            &after_hook,
            &bench_call,
            decls.sink_decl,
            decls.memory_decl,
            decls.memory_before,
            decls.memory_after,
        );
    }

    match bench.mode {
        BenchMode::Auto => {
            code.push_str(&format!(
                r#"fn bench_{fn_name}(_iterations: i64) -> BenchResult {{
{sink_decl}{memory_decl}{before_hook}{memory_before}
{warmup}
{auto_loop}
{sample_collection}
    let nanos_per_op = total_nanos as f64 / total_iterations as f64;
    let ops_per_sec = 1e9 / nanos_per_op;
{after_hook}
    BenchResult {{
        iterations: total_iterations as u64,
        total_nanos: total_nanos as u64,
        nanos_per_op,
        ops_per_sec,
{memory_result}        samples,
    }}
}}

"#,
                fn_name = fn_name,
                sink_decl = decls.sink_decl,
                memory_decl = decls.memory_decl,
                before_hook = before_hook,
                memory_before = decls.memory_before,
                warmup = shared::generate_warmup_loop(&bench_call, decls.sink_keepalive, each_hook, "100"),
                auto_loop = shared::generate_auto_mode_loop(
                    &bench_call,
                    decls.sink_keepalive,
                    each_hook,
                    bench.target_time_ms
                ),
                sample_collection = shared::generate_sample_collection(
                    &bench_call,
                    decls.sink_keepalive,
                    each_hook,
                    "1000",
                    "total_iterations"
                ),
                after_hook = after_hook,
                memory_result = memory_result,
            ));
        }
        BenchMode::Fixed => {
            code.push_str(&format!(
                r#"fn bench_{fn_name}(iterations: i64) -> BenchResult {{
    let mut samples: Vec<u64> = vec![0; iterations as usize];
{sink_decl}{memory_decl}{before_hook}{memory_before}
{warmup}
{fixed_loop}
{memory_after}
    let nanos_per_op = total_nanos as f64 / iterations as f64;
    let ops_per_sec = 1e9 / nanos_per_op;
{after_hook}
    BenchResult {{
        iterations: iterations as u64,
        total_nanos,
        nanos_per_op,
        ops_per_sec,
{memory_result}        samples,
    }}
}}

"#,
                fn_name = fn_name,
                sink_decl = decls.sink_decl,
                memory_decl = decls.memory_decl,
                before_hook = before_hook,
                memory_before = decls.memory_before,
                warmup = shared::generate_warmup_loop(
                    &bench_call,
                    decls.sink_keepalive,
                    each_hook,
                    &bench.warmup.to_string()
                ),
                fixed_loop = shared::generate_fixed_mode_loop(
                    &bench_call,
                    decls.sink_keepalive,
                    each_hook,
                    "iterations"
                ),
                memory_after = decls.memory_after,
                after_hook = after_hook,
                memory_result = memory_result,
            ));
        }
    }

    Ok(())
}

/// Generate a concurrent benchmark function
fn generate_concurrent_benchmark(
    code: &mut String,
    bench: &BenchmarkSpec,
    fn_name: &str,
    before_hook: &str,
    after_hook: &str,
    bench_call: &str,
    sink_decl: &str,
    memory_decl: &str,
    memory_before: &str,
    memory_after: &str,
) -> Result<()> {
    let concurrency = bench.concurrency;
    let memory_result = SinkMemoryDecls::memory_result_fields(bench.memory);

    code.push_str(&format!(
        r#"fn bench_{fn_name}(iterations: i64) -> BenchResult {{
{sink_decl}{memory_decl}{before_hook}{memory_before}
{concurrent}
{sample_collection}
{memory_after}
    let nanos_per_op = total_nanos as f64 / total_iterations as f64;
    let ops_per_sec = 1e9 / nanos_per_op;
{after_hook}
    BenchResult {{
        iterations: total_iterations as u64,
        total_nanos: total_nanos as u64,
        nanos_per_op,
        ops_per_sec,
{memory_result}        samples,
    }}
}}

"#,
        fn_name = fn_name,
        sink_decl = sink_decl,
        memory_decl = memory_decl,
        before_hook = before_hook,
        memory_before = memory_before,
        concurrent = shared::generate_concurrent_execution(
            bench_call,
            bench_call,
            concurrency,
            "iterations"
        ),
        sample_collection = shared::generate_sample_collection(
            bench_call,
            "",
            None,
            "100",
            "total_iterations"
        ),
        memory_after = memory_after,
        after_hook = after_hook,
        memory_result = memory_result,
    ));

    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;
    use poly_bench_dsl::parse;
    use poly_bench_ir::lower;

    #[test]
    fn test_generate_simple() {
        let source = r#"
suite hash {
    iterations: 1000
    warmup: 10
    
    fixture data {
        hex: "deadbeef"
    }
    
    bench keccak256 {
        rust: keccak256(&data)
    }
}
"#;
        let ast = parse(source, "test.bench").unwrap();
        let ir = lower(&ast, None).unwrap();
        let code = generate(&ir).unwrap();

        assert!(code.contains("fn main()"));
        assert!(code.contains("fn bench_hash_keccak256"));
        assert!(code.contains("DATA"));
    }

    #[test]
    fn test_generate_with_stdlib_constants() {
        let source = r#"
use std::constants

suite math {
    iterations: 100
    
    bench pi_calc {
        rust: compute(STD_PI)
    }
}
"#;
        let ast = parse(source, "test.bench").unwrap();
        let ir = lower(&ast, None).unwrap();
        let code = generate(&ir).unwrap();

        assert!(code.contains("STD_PI"));
        assert!(code.contains("STD_E"));
        assert!(code.contains("f64"));
        assert!(code.contains("3.14159"));
    }
}
